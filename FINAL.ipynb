{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71d50796-42e1-4502-b242-0cf7fb4f2c32",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DS Final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acb4250-1019-4acc-aaa5-783455a85e4d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4cdff8-7e8f-4551-bedb-9ddf14a6d175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.model_selection import KFold\n",
    "import geopandas as gpd\n",
    "import plotly.express as px\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b939bee-a25a-43d8-aa65-907399306e63",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Universal Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bb6902-5dba-4d95-bbd4-b79caadc9640",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HDR_JSON_PATH = 'data/hdr-data.json'\n",
    "DEMOCRACY_CSV_PATH = 'data/democracy-index-eiu.csv'\n",
    "HEALTHCARE_CSV_PATH = 'data/Healthcare-expenditure.csv'\n",
    "FDI_CSV_PATH = 'data/foreign-direct-investment-net-inflows-as-share-of-gdp.csv'\n",
    "UNEMPLOYMENT_CSV_PATH = 'data/Unemployment.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c896d764-8ba1-4f3b-af36-89ab9f273e88",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f6a299-932f-43d7-a48e-f9ee62db5ceb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_json(filepath):\n",
    "    \"\"\"Reads a JSON file and returns a DataFrame.\"\"\"\n",
    "    with open(filepath) as infile:\n",
    "        return pd.read_json(infile)\n",
    "\n",
    "def read_csv(filepath, skiprows=None):\n",
    "    \"\"\"Reads a CSV file and returns a DataFrame.\"\"\"\n",
    "    return pd.read_csv(filepath, skiprows=skiprows)\n",
    "\n",
    "def clean_column_names(df):\n",
    "    \"\"\"Strips whitespace and cleans up column names.\"\"\"\n",
    "    df.columns = df.columns.str.strip()\n",
    "    return df\n",
    "\n",
    "def melt_dataframe(df, id_vars, var_name, value_name):\n",
    "    \"\"\"Melts a DataFrame into a long format.\"\"\"\n",
    "    return pd.melt(df, id_vars=id_vars, var_name=var_name, value_name=value_name)\n",
    "\n",
    "def pivot_dataframe(df, index, columns, values):\n",
    "    \"\"\"Pivots a DataFrame into a wide format.\"\"\"\n",
    "    return df.pivot_table(index=index, columns=columns, values=values).reset_index()\n",
    "\n",
    "def rename_columns(df, rename_dict):\n",
    "    \"\"\"Renames columns based on a dictionary.\"\"\"\n",
    "    return df.rename(columns=rename_dict)\n",
    "\n",
    "def merge_dataframes(df1, df2, on, how='left'):\n",
    "    \"\"\"Merges two DataFrames.\"\"\"\n",
    "    return pd.merge(df1, df2, how=how, on=on)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cd3740-7c64-473c-9365-86833fcf9c64",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Preparing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634d47f1-128b-4ab9-ac7c-61c5f9a8302f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Specific Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaf1ee5-4606-415f-accf-c3f430adddca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_hdr_data(filepath):\n",
    "    df = read_json(filepath)\n",
    "    df = df[['country', 'countryIsoCode', 'year', 'indicator', 'value']]\n",
    "    df_pivoted = pivot_dataframe(df, index=['country', 'countryIsoCode', \n",
    "                                            'year'], columns='indicator',\n",
    "                                             values='value')\n",
    "    df_pivoted = rename_columns(df_pivoted, {'country': 'Country', \n",
    "                                             'countryIsoCode': 'Code', \n",
    "                                             'year': 'Year'})\n",
    "    return df_pivoted\n",
    "\n",
    "def process_democracy_data(filepath):\n",
    "    df = read_csv(filepath)\n",
    "    df = rename_columns(df, {'Entity': 'Country'})\n",
    "    return df\n",
    "\n",
    "def process_health_expenditure_data(filepath):\n",
    "    df = read_csv(filepath, skiprows=4)\n",
    "    df = clean_column_names(df)\n",
    "    df_melted = melt_dataframe(\n",
    "        df,\n",
    "        id_vars=['Country Name', 'Country Code', 'Indicator Name', \n",
    "                 'Indicator Code'],\n",
    "        var_name='Year',\n",
    "        value_name='Value'\n",
    "    )\n",
    "    df_pivoted = pivot_dataframe(df_melted, index=['Country Name', \n",
    "                                                   'Country Code', 'Year'], \n",
    "                                 columns='Indicator Name', values='Value')\n",
    "    return rename_columns(df_pivoted, {'Country Name': 'Country', \n",
    "                                       'Country Code': 'Code'})\n",
    "\n",
    "def process_fdi_data(filepath):\n",
    "    df = read_csv(filepath)\n",
    "    return rename_columns(df, {'Entity': 'Country'})\n",
    "\n",
    "def process_unemployment_data(filepath):\n",
    "    df = read_csv(filepath)\n",
    "    df.drop(columns=['Series Code'], inplace=True)\n",
    "    df = clean_column_names(df)\n",
    "    df.columns = [col.split(' ')[0] if ' [YR' in col else col for col in \n",
    "                  df.columns]\n",
    "    df_melted = melt_dataframe(df, id_vars=['Country Name', 'Country Code', \n",
    "                                            'Series Name'], var_name='Year', \n",
    "                               value_name='Value')\n",
    "    df_melted['Value'] = pd.to_numeric(df_melted['Value'], errors='coerce')\n",
    "    df_pivoted = pivot_dataframe(df_melted, index=['Country Name', \n",
    "                                                   'Country Code', 'Year'], \n",
    "                                 columns='Series Name', values='Value')\n",
    "    return rename_columns(df_pivoted, {'Country Name': 'Country', \n",
    "                                       'Country Code': 'Code'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca79c88-dd8b-4df9-b6e5-027681919a2d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Processing The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dbe469-bff6-4483-94ce-9ef839b8bc04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hdr_data = process_hdr_data(HDR_JSON_PATH)\n",
    "democracy_data = process_democracy_data(DEMOCRACY_CSV_PATH)\n",
    "health_expense_data = process_health_expenditure_data(HEALTHCARE_CSV_PATH)\n",
    "fdi_data = process_fdi_data(FDI_CSV_PATH)\n",
    "unemployment_data = process_unemployment_data(UNEMPLOYMENT_CSV_PATH)\n",
    "    \n",
    "# Ensuring 'Year' columns are of consistent type\n",
    "datasets = [hdr_data, democracy_data, health_expense_data, fdi_data, \n",
    "                unemployment_data]\n",
    "for df in datasets:\n",
    "    if 'Year' in df.columns:\n",
    "        df['Year'] = df['Year'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3baca5d-1483-4e59-9ffc-f8ea17effb86",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Exploring The Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d65cc4-1be6-4ddb-b596-069f91687b45",
   "metadata": {
    "tags": []
   },
   "source": [
    "### HDR Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc36741-15d6-4a71-acbe-981d883ad7eb",
   "metadata": {},
   "source": [
    "COLUMNS THAT HAVE LESS THAN 40% MISSING:\n",
    "\n",
    "Index(['Country', 'Code', 'Year',\n",
    "       'Adolescent Birth Rate (births per 1,000 women ages 15-19)',\n",
    "       'Carbon dioxide emissions per capita (production) (tonnes)',\n",
    "       'Coefficient of human inequality', 'Difference from HDI value (%)',\n",
    "       'Expected Years of Schooling (years)',\n",
    "       'Expected Years of Schooling, female (years)',\n",
    "       'Expected Years of Schooling, male (years)',\n",
    "       'Gender Development Index (value)', 'Gender Inequality Index (value)',\n",
    "       'Gross National Income Per Capita (2017 PPP$)',\n",
    "       'Gross National Income Per Capita, female (2017 PPP$)',\n",
    "       'Gross National Income Per Capita, male (2017 PPP$)', 'HDI female',\n",
    "       'HDI male', 'Human Development Index (value)', 'Inequality in eduation',\n",
    "       'Inequality in income', 'Inequality in life expectancy',\n",
    "       'Inequality-adjusted Human Development Index (value)',\n",
    "       'Labour force participation rate, female (% ages 15 and older)',\n",
    "       'Labour force participation rate, male (% ages 15 and older)',\n",
    "       'Life Expectancy at Birth (years)',\n",
    "       'Life Expectancy at Birth, female (years)',\n",
    "       'Life Expectancy at Birth, male (years)',\n",
    "       'Material footprint per capita (tonnes)',\n",
    "       'Maternal Mortality Ratio (deaths per 100,000 live births)',\n",
    "       'Mean Years of Schooling (years)',\n",
    "       'Mean Years of Schooling, female (years)',\n",
    "       'Mean Years of Schooling, male (years)', 'Overall loss (%)',\n",
    "       'Planetary pressures–adjusted Human Development Index (value)',\n",
    "       'Population with at least some secondary education, female (% ages 25 and older)',\n",
    "       'Population with at least some secondary education, male (% ages 25 and older)',\n",
    "       'Share of seats in parliament, female (% held by women)',\n",
    "       'Share of seats in parliament, male (% held by men)'],\n",
    "      dtype='object', name='indicator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5dff81-15e6-4a6d-977f-4e48fd5aa71f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To substitute a different data source for exploration, simply change the string located...\n",
    "\n",
    "data_to_explore = hdr_data # < ...here\n",
    "\n",
    "data_to_explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aacf187-dce9-49b6-858f-ff592c655088",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_to_explore.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1f0839-3f88-48ac-8d27-a76d7a74b7b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filter rows for a range years (currently 2013-2022)\n",
    "filtered_data = data_to_explore[(data_to_explore['Year'] >= 2011) & (data_to_explore['Year'] <= 2023)]\n",
    "\n",
    "# Step 2: Drop columns with more than 20% missing data\n",
    "threshold = 0.4  # 40% missing data threshold\n",
    "missing_data_ratio = filtered_data.isnull().mean()  \n",
    "columns_to_keep = missing_data_ratio[missing_data_ratio <= threshold].index\n",
    "\n",
    "# Filter the dataset\n",
    "cleaned_data = filtered_data[columns_to_keep]\n",
    "\n",
    "# Check the resulting dataset structure\n",
    "print(f\"Columns with less than {threshold * 100}% of data missing:\")\n",
    "print(cleaned_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a177484-46ff-4c04-a0f0-b42b72db429f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Merging the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1d18be-af48-4c49-975f-c4600d4c35d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_df = hdr_data\n",
    "merged_df = merge_dataframes(merged_df, democracy_data, on=['Country', 'Code', 'Year'])\n",
    "merged_df = merge_dataframes(merged_df, health_expense_data, on=['Country', 'Code', 'Year'])\n",
    "merged_df = merge_dataframes(merged_df, fdi_data, on=['Country', 'Code', 'Year'])\n",
    "merged_df = merge_dataframes(merged_df, unemployment_data, on=['Country', 'Code', 'Year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539a9d6e-6e0a-46f5-8e7c-8e9a923dadf1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## More of Cleaning The Data, and Preventing Overfitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7e557f-fce4-499a-a792-ec8696cf89de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Step 1: Selecting only the years in the Target Dataset: 2013 - 2022\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d83a7d-59be-42ee-914b-8d03c0a75aec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_post_2013 = merged_df[(merged_df['Year'] >= 2013) & (merged_df['Year'] <= 2022)]\n",
    "df_post_2013.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f259dcd-c199-44b1-935e-ef4d23d22e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_post_2013"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3300013e-deaf-4f93-8486-cf6adeb6f862",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Step 2: Finding the optimal threshold for NaN values for which we can drop a column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3acec0b-c515-49e3-a22e-7f1136d4e89d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ee970c-e0c3-41bd-8264-fcd4cdbfd2f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def drop_nans(df, threshold):\n",
    "    \"\"\"\n",
    "    Drops columns from a DataFrame where the number of NaN values exceeds the threshold (int).\n",
    "    \n",
    "    Returns a pd.DataFrame with just the columns exceeding the threshold dropped.\n",
    "    \"\"\"\n",
    "    return df.loc[:, df.isna().sum() <= threshold]\n",
    "\n",
    "#The below function will help identify the optimal NaN drop boundary\n",
    "          \n",
    "def visualize_nan_and_columns(df, thresholds):\n",
    "    \"\"\"\n",
    "    Visualizes the relationship between NaN thresholds, number of columns left, \n",
    "    and the remaining NaN values using a dual-axis plot.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        thresholds (list[int]): A list of threshold values to test.\n",
    "\n",
    "    Returns:\n",
    "        None: Displays a dual-axis line graph.\n",
    "    \"\"\"\n",
    "    column_counts = []\n",
    "    nan_counts = []  \n",
    "\n",
    "    for threshold in thresholds:\n",
    "        reduced_df = drop_nans(df, threshold)\n",
    "        column_counts.append(reduced_df.shape[1])  # Number of columns in reduced DataFrame\n",
    "        nan_counts.append(reduced_df.isna().sum().sum())\n",
    "\n",
    "   \n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Number of columns left\n",
    "    ax1.plot(thresholds, column_counts, color='green', marker='o', label='Columns Left')\n",
    "    ax1.set_xlabel('Threshold (Maximum NaN Values Per Column)', fontsize=12)\n",
    "    ax1.set_ylabel('Number of Columns Left', color='green', fontsize=12)\n",
    "    ax1.tick_params(axis='y', labelcolor='green')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Remaining NaN values\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(thresholds, nan_counts, color='blue', marker='x', label='Remaining NaN Values')\n",
    "    ax2.set_ylabel('Total Remaining NaN Values', color='blue', fontsize=12)\n",
    "    ax2.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "    plt.title('Effect of NaN Threshold on Columns and Remaining NaNs', fontsize=14)\n",
    "    ax1.legend(loc='upper left')\n",
    "    ax2.legend(loc='upper right')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Thresholds from 0 to the max NaNs in increments of 100\n",
    "threshold_range = range(0, df_post_2013.isna().sum().max() + 100, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8270c1d6-2fc8-4bbc-beac-a642ea55a2bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Plotting NaN threshold vs. remaining NaN values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaad50da-7e9d-4984-9f9f-36837ae3e540",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_nan_and_columns(df_post_2013, threshold_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ebe88e-df25-42e0-ac44-9ba5a4774e94",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Based on this, we can reduce NaN values by almost 90% by setting the threshold to drop a column at 200, while still retaining over 50% of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf97e37-4cc9-40c7-ac66-254e41f7d8c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_optimal = drop_nans(df_post_2013,200)\n",
    "# Viable features are -\n",
    "print(df_optimal.columns, len(df_optimal.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e97943-9023-4b3d-8617-a4dfde82729c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Step 3: Do a domain-specific drop, by dropping all features represented by a composite index (GDI) in the cleaned list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0fbbf2-36a4-4534-a005-c8940b15e1d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "redundant_features_GDI = [\n",
    "    'Expected Years of Schooling, female (years)',\n",
    "    'Expected Years of Schooling, male (years)',\n",
    "    'Gross National Income Per Capita, female (2017 PPP$)',\n",
    "    'Gross National Income Per Capita, male (2017 PPP$)',\n",
    "    'Life Expectancy at Birth, female (years)',\n",
    "    'Life Expectancy at Birth, male (years)',\n",
    "    'HDI female',\n",
    "    'HDI male',\n",
    "    'Labour force participation rate, female (% ages 15 and older)',\n",
    "    'Labour force participation rate, male (% ages 15 and older)',\n",
    "    'Share of seats in parliament, female (% held by women)',\n",
    "    'Share of seats in parliament, male (% held by men)',\n",
    "    'Population with at least some secondary education, female (% ages 25 and older)',\n",
    "    'Population with at least some secondary education, male (% ages 25 and older)',\n",
    "    'Mean Years of Schooling, female (years)',\n",
    "    'Mean Years of Schooling, male (years)'\n",
    "]\n",
    "\n",
    "#We can also drop HDI, and focus on the effect of its composite factors, as they may not be correlated\n",
    "HDI_column = ['Human Development Index (value)']\n",
    "\n",
    "redundant_features = redundant_features_GDI + HDI_column\n",
    "print(redundant_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9c80c3-7f01-4572-bd99-470152baf40c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_indexed = df_optimal.drop(redundant_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05a8586-caae-40f7-a0a9-b29d50e2a7f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_features = df_indexed.drop(['Country', 'Code', 'Year'],axis = 1)\n",
    "corr_matrix = df_features.corr()\n",
    "corr_matrix\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='RdBu', fmt='.2f', linewidths=0.4)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "corr_matrix.abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188ad019-b707-47fd-8199-7c678c364f6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641ba30f-0231-4b13-a33e-a6bec9003d59",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Based on the correlation matrix & pairplot above, we should drop \"Inequality in life expectancy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aef9d52-95b0-43cc-b30c-682dc6360918",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_clean = df_indexed.drop('Inequality in life expectancy', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e985ca1c-5ab0-4aac-8404-e3a5d22e61d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1ec734-12fb-4003-b658-fed91b457372",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Combining Happiness Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a254dc-360d-474b-b629-98361330bfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the combined happiness data\n",
    "happiness_data = pd.read_csv('data/combined_happiness_data_filtered.csv')\n",
    "\n",
    "# Merge the data\n",
    "happiness_df = pd.merge(\n",
    "    df_clean,\n",
    "    happiness_data,\n",
    "    on=['Country', 'Year'],  # Merge on these columns\n",
    "    how='inner'  # Use 'inner' to keep only matching rows\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859467cc-2254-4c90-9404-02b1831acd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "happiness_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b7b985-04eb-4e04-8439-b3b8aee473b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where 'Happiness Score' is NaN (should be none, since we determined to do so in our parameters above)\n",
    "happiness_df = happiness_df.dropna(subset=['Happiness Score'])\n",
    "happiness_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b500cb-6134-4619-a4ba-57406afe48fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save merged DataFrame\n",
    "happiness_df.to_csv('data/final_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afacf84d-2a86-4007-a292-77bf59732d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Remaining rows before dropping: {happiness_df.shape[0]}\")\n",
    "\n",
    "# Drop rows with missing data in any column\n",
    "cleaned_df = happiness_df.dropna()\n",
    "\n",
    "print(f\"Remaining rows after dropping: {cleaned_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84478fef-bd41-47d1-8502-97305e14b06f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47af87df-3198-4ccc-8181-f425e7dc6d65",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creating Training and Testing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abd7c25-5d22-4ad4-bf5d-76ea61232fdd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0164e0-507b-4730-84b6-4f2536856c08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detect_relationship(data, feature, target):\n",
    "    \"\"\"\n",
    "    Determines the best-fitting relationship between a feature and the target: linear, logarithmic, or exponential.\n",
    "\n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): The dataset containing the feature and target columns.\n",
    "    - feature (str): The name of the feature column.\n",
    "    - target (str): The name of the target column.\n",
    "\n",
    "    Returns:\n",
    "    - str: The type of relationship ('linear', 'logarithmic', or 'exponential') that best fits the data.\n",
    "    \"\"\"\n",
    "    X = data[[feature]].copy()\n",
    "    y = data[target]\n",
    "    \n",
    "    relationships = {}\n",
    "\n",
    "    # Linear Model\n",
    "    linear_model = LinearRegression()\n",
    "    linear_model.fit(X, y)\n",
    "    y_pred_linear = linear_model.predict(X)\n",
    "    r2_linear = r2_score(y, y_pred_linear)\n",
    "    relationships['linear'] = r2_linear\n",
    "\n",
    "    # Logarithmic Model (log of feature)\n",
    "    if (X[feature] > 0).all():  # Ensure positive values for log transformation\n",
    "        log_X = np.log(X)\n",
    "        log_model = LinearRegression()\n",
    "        log_model.fit(log_X, y)\n",
    "        y_pred_log = log_model.predict(log_X)\n",
    "        r2_log = r2_score(y, y_pred_log)\n",
    "        relationships['logarithmic'] = r2_log\n",
    "    else:\n",
    "        relationships['logarithmic'] = float('-inf')\n",
    "\n",
    "    # Exponential Model (log of target)\n",
    "    if (y > 0).all():  # Ensure positive values for exponential model\n",
    "        log_y = np.log(y)\n",
    "        exp_model = LinearRegression()\n",
    "        exp_model.fit(X, log_y)\n",
    "        y_pred_exp = np.exp(exp_model.predict(X))\n",
    "        r2_exp = r2_score(y, y_pred_exp)\n",
    "        relationships['exponential'] = r2_exp\n",
    "    else:\n",
    "        relationships['exponential'] = float('-inf')  # Invalid option for this target\n",
    "\n",
    "    # Determine the best relationship based on R²\n",
    "    best_relationship = max(relationships, key=relationships.get)\n",
    "    return best_relationship, relationships\n",
    "\n",
    "def detect_all_relationships(X, y, target_name='Target'):\n",
    "    \"\"\"\n",
    "    Detects the best-fitting relationship type for each feature in X with respect to the target variable y.\n",
    "\n",
    "    Parameters:\n",
    "    - X (pd.DataFrame): DataFrame containing the feature columns.\n",
    "    - y (pd.Series): Series containing the target variable.\n",
    "    - target_name (str): Name of the target variable (default is 'Target').\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary where keys are feature names and values are the best-fitting relationship type.\n",
    "    \"\"\"\n",
    "    # Combine features (X) and target (y) into a single DataFrame\n",
    "    data = pd.concat([X, y.rename(target_name)], axis=1)\n",
    "\n",
    "    # Dictionary to store relationships\n",
    "    relationships = {}\n",
    "\n",
    "    # Iterate through each feature column\n",
    "    for feature in X.columns:\n",
    "        best_relationship, _ = detect_relationship(data, feature, target_name)\n",
    "        relationships[feature] = best_relationship\n",
    "\n",
    "    return relationships\n",
    "\n",
    "def get_relationship_dict(X, y):\n",
    "    relationship_dict = {}\n",
    "    \n",
    "    # Combine the features and target into one DataFrame\n",
    "    relationship_data = pd.concat([X, y], axis=1)\n",
    "\n",
    "    for feature in X.columns:\n",
    "        relationship, scores = detect_relationship(relationship_data, feature, y.name)\n",
    "        relationship_dict[relationship] = feature\n",
    "    \n",
    "    return relationship_dict\n",
    "\n",
    "def preprocess_data(X, log_features=[], exp_features=[]):\n",
    "    \"\"\"\n",
    "    Preprocess data by applying transformations and scaling.\n",
    "\n",
    "    Parameters:\n",
    "    X : pd.DataFrame\n",
    "        Input dataframe with features to preprocess.\n",
    "    log_features : list\n",
    "        Features to apply log(1 + x) transformation.\n",
    "    exp_features : list\n",
    "        Features to apply exp(x) transformation.\n",
    "    Returns:\n",
    "    np.ndarray\n",
    "        Scaled NumPy array of the preprocessed features.\n",
    "    \"\"\"\n",
    "    X_transformed = X.copy()\n",
    "    \n",
    "    # Log transformation\n",
    "    X_transformed[log_features] = X[log_features].apply(np.log1p)\n",
    "    \n",
    "    # Exponential transformation\n",
    "    X_transformed[exp_features] = X[exp_features].apply(np.exp)\n",
    "    \n",
    "    # Standard scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_transformed)\n",
    "    \n",
    "    return X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e21906d-3408-4947-8917-ac2f04e2c3dd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abef8dfa-5fc2-46ee-be8a-06eac645b1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = cleaned_df.drop(['Country', 'Code', 'Year'],axis = 1)\n",
    "\n",
    "#Splitting data into features and target\n",
    "X = df_ml.drop(columns=['Happiness Score'])  # Features: all columns except the target\n",
    "y = df_ml['Happiness Score']                 # Target: Happiness Score\n",
    "\n",
    "#Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Scaling the Data\n",
    "X_train_scaled = preprocess_data(X_train)\n",
    "X_test_scaled = preprocess_data(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7057c8-065e-43f7-a91f-5dcc56b5ead5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Identifying and transforming exponential relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27f99ff-0caf-4217-82a7-97c28047e4cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "relationship_data = pd.concat([X, y], axis=1)\n",
    "\n",
    "relationship_dict = {}\n",
    " # Iterate through each feature column\n",
    "for feature in X.columns:\n",
    "    relationship, scores = detect_relationship(relationship_data, feature, y.name)\n",
    "        \n",
    " # Append the feature to the appropriate relationship list\n",
    "    if relationship in relationship_dict:\n",
    "        relationship_dict[relationship].append(feature)\n",
    "    else:\n",
    "        relationship_dict[relationship] = [feature]\n",
    "relationship_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7ae76b-b3f8-4d43-aa93-4daf6b3ea2ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the features to be transformed\n",
    "log_features = relationship_dict['logarithmic']\n",
    "exp_features = relationship_dict['exponential']\n",
    "\n",
    "# Preprocessin data (includes log, exp transformations, and scaling)\n",
    "X_train_trans = preprocess_data(X_train, log_features, exp_features)\n",
    "X_test_trans = preprocess_data(X_test, log_features, exp_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b75d831-d9cb-40cd-9d74-d1b7459144b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Training some models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cad1022-9ff7-4f66-bb8a-a5d7635e66be",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41984a4a-8818-45f9-b817-767e13a856fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model_type, X_train, y_train, **model_kwargs):\n",
    "    \"\"\"\n",
    "    Train a single model on the provided training data.\n",
    "    \n",
    "    Parameters:\n",
    "    - model_type (str): Type of the model ('linear_regression', 'decision_tree', 'random_forest').\n",
    "    - X_train, y_train: Training data.\n",
    "    - model_kwargs: Additional arguments for model initialization.\n",
    "    \n",
    "    Returns:\n",
    "    - model: The trained model.\n",
    "    \"\"\"\n",
    "    if model_type == \"linear_regression\":\n",
    "        model = LinearRegression(**model_kwargs)\n",
    "    elif model_type == \"decision_tree\":\n",
    "        model = DecisionTreeRegressor(**model_kwargs)\n",
    "    elif model_type == \"random_forest\":\n",
    "        model = RandomForestRegressor(**model_kwargs)\n",
    "    elif model_type == \"deeap_learning\":\n",
    "        model = RandomForestRegressor(**model_kwargs)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d51456-3037-442d-9a88-7279085c2782",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cd27a2-a09a-4079-881f-2539a021900c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lin_model = train_model(\"linear_regression\", X_train_scaled, y_train)\n",
    "trans_lin_model = train_model(\"linear_regression\", X_train_trans, y_train)\n",
    "tree_model = train_model(\"decision_tree\", X_train, y_train)\n",
    "rf_model = train_model(\"random_forest\", X_train, y_train, n_estimators=100,random_state = 42)\n",
    "models = [rf_model, tree_model, lin_model, trans_lin_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07153e58-c8a0-4f9a-a801-2cd7e8856a50",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Evaluating these models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183e0c0b-cbef-4944-ad06-f6e8d9cd2f0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f591bb-12e2-4f3e-b009-1bd2b9405411",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def linreg_eval(model, X, y, transform=False, cv=5):\n",
    "    \"\"\"\n",
    "    Perform cross-validation with optional transformations.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : object\n",
    "        The model to train and evaluate (e.g., LinearRegression, \n",
    "        RandomForestRegressor).\n",
    "    X : pd.DataFrame\n",
    "        The feature dataset.\n",
    "    y : array-like\n",
    "        The target variable.\n",
    "    transform : bool, default=False\n",
    "        Whether to apply log and exp transformations during preprocessing.\n",
    "    cv : int, default=5\n",
    "        Number of cross-validation folds.\n",
    "    model_name : str, default=\"Model\"\n",
    "        Name of the model (for inclusion in the results).\n",
    "    Returns:\n",
    "    --------\n",
    "    metrics : dict\n",
    "        Cross-validation metrics including RMSE and R² (mean and std).\n",
    "    \"\"\"\n",
    "    y = np.array(y)\n",
    "    # Lists to store scores\n",
    "    rmse_scores = []\n",
    "    r2_scores = []\n",
    "\n",
    "    # K-Fold cross-validation\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        # Split data\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # Preprocess data\n",
    "        if transform == False:\n",
    "            X_train_preprocessed = preprocess_data(X_train)\n",
    "            X_test_preprocessed = preprocess_data(X_test)\n",
    "        \n",
    "        else: \n",
    "            X_train_preprocessed = preprocess_data(X_train, \n",
    "                                               log_features, \n",
    "                                               exp_features)\n",
    "            X_test_preprocessed = preprocess_data(X_test,\n",
    "                                              log_features, \n",
    "                                              exp_features)\n",
    "        # Train the model\n",
    "        model.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "        # Predict and evaluate\n",
    "        y_pred = model.predict(X_test_preprocessed)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        # Store metrics\n",
    "        rmse_scores.append(rmse)\n",
    "        r2_scores.append(r2)\n",
    "\n",
    "    # Compile metrics\n",
    "    metrics = {\n",
    "        \"CV_RMSE_Mean\": np.mean(rmse_scores),\n",
    "        \"CV_RMSE_Std\": np.std(rmse_scores),\n",
    "        \"CV_R2_Mean\": np.mean(r2_scores),\n",
    "        \"CV_R2_Std\": np.std(r2_scores),\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def evaluate_model(model, X, y, cv=5):\n",
    "    \"\"\"\n",
    "    Perform cross-validation on a trained model and calculate evaluation metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: The trained model.\n",
    "    - X, y: Dataset for cross-validation.\n",
    "    - cv (int): Number of cross-validation folds.\n",
    "    \n",
    "    Returns:\n",
    "    - metrics (dict): Cross-validation metrics (mean and std for RMSE and R²).\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    cv_rmse_scores = -cross_val_score(model, X, y, scoring=\"neg_root_mean_squared_error\", cv=cv)\n",
    "    cv_r2_scores = cross_val_score(model, X, y, scoring=\"r2\", cv=cv)\n",
    "\n",
    "    metrics = {\n",
    "        \"CV_RMSE_Mean\": np.mean(cv_rmse_scores),\n",
    "        \"CV_RMSE_Std\": np.std(cv_rmse_scores),\n",
    "        \"CV_R2_Mean\": np.mean(cv_r2_scores),\n",
    "        \"CV_R2_Std\": np.std(cv_r2_scores),\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def compare_evaluations(results):\n",
    "    \"\"\"\n",
    "    Compare evaluation results for multiple models.\n",
    "    \n",
    "    Parameters:\n",
    "    - results (dict): Dictionary where keys are model names and values are their evaluation metrics.\n",
    "    \n",
    "    Returns:\n",
    "    - comparison_df (pd.DataFrame): Summary DataFrame comparing all models.\n",
    "    \"\"\"\n",
    "    comparison_data = []\n",
    "    for model_name, metrics in results.items():\n",
    "        metrics[\"Model\"] = model_name\n",
    "        comparison_data.append(metrics)\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    return comparison_df\n",
    "\n",
    "def plot_rmse(all_metrics):\n",
    "    \"\"\"\n",
    "    Plot the RMSE (CV_RMSE_Mean) of each model.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    all_metrics : dict\n",
    "        Dictionary containing model names as keys and their evaluation metrics as values.\n",
    "    \"\"\"\n",
    "    # Extract model names and RMSE means\n",
    "    models = list(all_metrics.keys())\n",
    "    rmse_means = [metrics[\"CV_RMSE_Mean\"] for metrics in all_metrics.values()]\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(models, rmse_means, alpha=0.8)\n",
    "    plt.ylabel(\"CV_RMSE_Mean\")\n",
    "    plt.xlabel(\"Models\")\n",
    "    plt.title(\"Cross-Validation RMSE Mean for Each Model\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc79c104-60e0-4827-90a7-40e50ceaf776",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluating and Comparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac4ec7c-291f-4d7f-aafd-fd72f277181d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf_metrics = evaluate_model(rf_model, X, y, cv=5)\n",
    "tree_metrics = evaluate_model(tree_model, X, y)\n",
    "linreg_metrics = linreg_eval(lin_model, X, y)\n",
    "trans_linreg_metrics = linreg_eval(trans_lin_model, X, y, transform = True)\n",
    "\n",
    "model_names = [\"Random Forest\",\"Decision Tree\",\"Linear\",\"Linear Transformed\"]\n",
    "metrics = [rf_metrics,tree_metrics,linreg_metrics,trans_linreg_metrics]\n",
    "all_metrics = {model_name: metric for model_name, metric in zip(model_names, metrics)}\n",
    "\n",
    "#Comparing Metrics\n",
    "plot_rmse(all_metrics)\n",
    "(compare_evaluations(all_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85bd873-0872-44f9-853b-5cfd6cb4fa26",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Examining the Weights from each model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc23180-17f8-4852-838c-44b5d6e0ee55",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae11191-f2c1-43da-a07b-2bbfc13f944f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_model_feature_importance(model, feature_names, title=\"Feature Importance\"):\n",
    "    \"\"\"\n",
    "    Plot feature importance or coefficients for a Linear Regression, Decision Tree, or Random Forest model.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model: object\n",
    "        Trained model (LinearRegression, DecisionTreeRegressor, RandomForestRegressor, etc.).\n",
    "    feature_names: list\n",
    "        List of feature names corresponding to the input features.\n",
    "    title: str, default=\"Feature Importance\"\n",
    "        Title for the plot.\n",
    "    \"\"\"\n",
    "\n",
    "    if hasattr(model, \"feature_importances_\"):  # Tree-based models\n",
    "        importances = abs(model.feature_importances_)\n",
    "        sorted_indices = np.argsort(importances)\n",
    "        scores = importances[sorted_indices]\n",
    "        feature_labels = [feature_names[i] for i in sorted_indices]\n",
    "        xlabel = \"Feature Importance\"\n",
    "        color = \"seagreen\"\n",
    "        \n",
    "    elif hasattr(model, \"coef_\"):  # Linear models\n",
    "        importances = abs(model.coef_)\n",
    "        sorted_indices = np.argsort(np.abs(importances))  # Sort by absolute value\n",
    "        scores = importances[sorted_indices]\n",
    "        feature_labels = [feature_names[i] for i in sorted_indices]\n",
    "        xlabel = \"Feature Coefficient\"\n",
    "        color = \"indianred\"\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(range(len(scores)), scores, align=\"center\", color = color)\n",
    "    plt.yticks(range(len(scores)), feature_labels)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(\"Features\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19f7352-f15e-4260-815b-8491d1fc4215",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plotting the importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab99264f-be16-4c91-bcbc-db83c2e0172a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Loop through models and model names\n",
    "for model, model_name in zip(models, model_names):\n",
    "    # Plot feature importance or coefficients for each model\n",
    "    print(f\"Plotting feature importance for: {model_name}\")\n",
    "    plot_model_feature_importance(model, X.columns, title=f\"Feature Importance: {model_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470d69a0-0da5-489e-a6d6-58774011e051",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Predicting Missing Happiness Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d8c839-52fe-4ecc-acf6-3e807e9f56ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_full = merged_df\n",
    "common_columns = df_full.columns.intersection(df_clean.columns)\n",
    "df_full = df_full[common_columns].dropna()\n",
    "prehappy_features = df_full.drop([\"Code\",\"Year\",\"Country\"], axis = 1)\n",
    "prehappy_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9990f0a-dbb4-45b6-812f-6889bec6fbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict happiness scores using the Random Forest model\n",
    "happiness_predictions = rf_model.predict(prehappy_features)\n",
    "\n",
    "# Create a new DataFrame with predictions\n",
    "prehappy_predictions = df_full[[\"Code\", \"Year\", \"Country\"]].copy()\n",
    "prehappy_predictions[\"Predicted Happiness\"] = happiness_predictions\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "prehappy_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c293152-ea21-422f-a2c2-9c8127f32b2c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Visualising and Exploring the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e706b2b2-00b9-4558-9103-f9dd7681fdc2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Combine DataFrames for Predicted, Actual, and Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d5b2f3-16cf-420a-981d-4c05b1a974b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_df = prehappy_predictions[[\"Code\", \"Year\", \"Country\", \"Predicted Happiness\"]].merge(\n",
    "    happiness_df[[\"Code\", \"Year\", \"Happiness Score\"]], \n",
    "    on=[\"Code\", \"Year\"],\n",
    "    how=\"left\" \n",
    ")\n",
    "\n",
    "# Calculate the difference between actual and predicted happiness\n",
    "combined_df[\"Happiness Difference\"] = combined_df[\"Happiness Score\"] - combined_df[\"Predicted Happiness\"]\n",
    "\n",
    "# Display the combined DataFrame\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23835640-349e-4da6-b27e-4834f1821a29",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Calculate Mean Happiness Per Country Across Years\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15fedec-bf88-46ae-aedd-b609f4b1d24f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_happiness_df = combined_df.groupby(\"Code\", as_index=False).agg(\n",
    "    Mean_Actual_Happiness=(\"Happiness Score\", lambda x: x.dropna().mean()),\n",
    "    Mean_Predicted_Happiness=(\"Predicted Happiness\", \"mean\"),\n",
    "    Mean_Happiness_Difference=(\"Happiness Difference\", lambda x: x.dropna().mean())\n",
    ")\n",
    "mean_happiness_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49680ae8-031f-4ca2-8986-577ebcf2777c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Testing the similarity of World predicted vs. World actual happiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9908f0d4-b1ab-4e71-82ed-6d394f46e71a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "world_happiness_per_year = combined_df.dropna(subset=[\"Happiness Score\"]).groupby(\"Year\", as_index=False).agg(\n",
    "    Mean_World_Actual_Happiness=(\"Happiness Score\", \"mean\"),\n",
    "    Mean_World_Predicted_Happiness=(\"Predicted Happiness\", \"mean\"),\n",
    "    Mean_World_Happiness_Difference=(\"Happiness Difference\", \"mean\")\n",
    ")\n",
    "print('The average difference in predicted vs. actual is:'\n",
    "      ,world_happiness_per_year.Mean_World_Happiness_Difference.abs().mean())\n",
    "world_happiness_per_year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7fd927-2011-49d5-a4b2-3f88b439b6fa",
   "metadata": {},
   "source": [
    "### Creating a dataframe of perdicted world happiness over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77f6951-dd87-4049-b80c-7a3ed35680ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "world_predicted_happiness = combined_df.groupby(\"Year\", as_index=False).agg(\n",
    "    Mean_World_Predicted_Happiness=(\"Predicted Happiness\", \"mean\")\n",
    ")\n",
    "world_predicted_happiness.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ae9a49-3981-4857-bdaa-cbfcddc93072",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a29bd005-eb26-4220-9b3b-ff62bc0ccbe9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(world_happiness_per_year[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[1;32m      3\u001b[0m          world_happiness_per_year[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean_World_Actual_Happiness\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[1;32m      4\u001b[0m          label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mActual Happiness\u001b[39m\u001b[38;5;124m\"\u001b[39m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(world_happiness_per_year[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[1;32m      7\u001b[0m          world_happiness_per_year[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean_World_Predicted_Happiness\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      8\u001b[0m          label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Happiness\u001b[39m\u001b[38;5;124m\"\u001b[39m, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(world_happiness_per_year[\"Year\"], \n",
    "         world_happiness_per_year[\"Mean_World_Actual_Happiness\"], \n",
    "         label=\"Actual Happiness\", marker=\"o\")\n",
    "\n",
    "plt.plot(world_happiness_per_year[\"Year\"], \n",
    "         world_happiness_per_year[\"Mean_World_Predicted_Happiness\"],\n",
    "         label=\"Predicted Happiness\", linestyle=\"--\", marker=\"x\")\n",
    "\n",
    "plt.title(\"Global Happiness Trends Over Time\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Happiness Score\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c97b939-aa39-4fc6-8373-9d70bb9ebab1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(world_predicted_happiness[\"Year\"], \n",
    "         world_predicted_happiness[\"Mean_World_Predicted_Happiness\"],\n",
    "         label=\"Predicted Happiness\", color = \"green\")\n",
    "\n",
    "plt.title(\"Predicted Global Happiness Trends Over Time\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Happiness Score\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba68f3ff-368f-48c6-a446-bc46fd4f08cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_happiness_sorted = mean_happiness_df.sort_values(\"Mean_Happiness_Difference\")\n",
    "\n",
    "# Identify top 10 overperformers and underperformers\n",
    "top_overperformers = mean_happiness_sorted.nlargest(10, \"Mean_Happiness_Difference\")\n",
    "top_underperformers = mean_happiness_sorted.nsmallest(10, \"Mean_Happiness_Difference\")\n",
    "\n",
    "combined_top_countries = pd.concat([top_overperformers, top_underperformers])\n",
    "\n",
    "# Plot combined bar graph\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = [\"blue\" if diff > 0 else \"red\" for diff in combined_top_countries[\"Mean_Happiness_Difference\"]]\n",
    "plt.bar(combined_top_countries[\"Code\"], combined_top_countries[\"Mean_Happiness_Difference\"], color=colors)\n",
    "plt.axhline(0, color=\"black\", linestyle=\"--\", linewidth=0.8)\n",
    "plt.title(\"Top 10 Overperforming and Underperforming Countries (Actual - Predicted Happiness)\")\n",
    "plt.xlabel(\"Country\")\n",
    "plt.ylabel(\"Happiness Difference\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis=\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49609ced-44df-43fa-9087-2d4a3a959fed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=combined_df.where(combined_df.Year >= 2013),\n",
    "            x=\"Year\", y=\"Happiness Score\", color=\"cornflowerblue\", width=0.6)\n",
    "sns.boxplot(data=combined_df.where(combined_df.Year >= 2013),\n",
    "            x=\"Year\", y=\"Predicted Happiness\", color=\"salmon\", width=0.4)\n",
    "plt.title(\"Distribution of Happiness Scores by Year\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Happiness Score\")\n",
    "plt.legend([\"Actual Happiness\", \"Predicted Happiness\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb5c541-9664-4df0-97c3-4c2f3d1a7495",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ERROR: Geopandas latest update breaks \"fiona\" in the .get_path portion. Solution tbd.\n",
    "\n",
    "\n",
    "def create_heatmap(df, country_col, value_col, title=\"Country Heatmap\"):\n",
    "    \"\"\"\n",
    "    Create a heatmap over a world map based on country codes and associated values from a dataframe.\n",
    "    \n",
    "    :param df: DataFrame containing the country codes and their corresponding values.\n",
    "    :param country_col: The column name in the dataframe containing the country codes (ISO 3166-1 alpha-3).\n",
    "    :param value_col: The column name in the dataframe containing the values (e.g., GDP, Happiness Score, etc.).\n",
    "    :param title: Title for the heatmap.\n",
    "    :return: A plotly figure object showing the heatmap on the world map.\n",
    "    \"\"\"\n",
    "    # Load world map data using geopandas\n",
    "    world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "    \n",
    "    # Merge world map data with the input dataframe based on country code\n",
    "    world = world.merge(df, how='left', left_on='iso_a3', right_on=country_col)\n",
    "\n",
    "    # Plot the heatmap using plotly\n",
    "    fig = px.choropleth(world, locations='iso_a3', color=value_col,\n",
    "                        hover_name='name', hover_data=[value_col],\n",
    "                        title=title)\n",
    "    \n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "    \n",
    "\n",
    "create_heatmap(mean_happiness_df, \"Code\",\"Mean_Predicted_Happiness\",title = \"Mean Predicted Happiness Heatmap\")\n",
    "create_heatmap(mean_happiness_df,\"Code\", \"Mean_Actual_Happiness\", title = \"Mean Actual Happiness Heatmap\")\n",
    "create_heatmap(\n",
    "    df=mean_happiness_df,\n",
    "    country_col=\"Code\",  # Replace with the actual column name for country codes\n",
    "    value_col=\"Mean_Happiness_Difference\",  # Replace with the actual column name for happiness difference\n",
    "    title=\"Happiness Performance Heatmap\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9274c46-d714-4080-aa01-928358c6632f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Deep Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8592cff3-45f2-42b4-961f-fc24d61c6a1c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Basic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be373efe-f214-43d1-bef8-fe002de3b2e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = cleaned_df.drop(['Country', 'Code', 'Year'], axis = 1)\n",
    "X = df.drop(columns=['Happiness Score'])\n",
    "y = df['Happiness Score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(48, input_dim=X_train_scaled.shape[1], activation='relu'), \n",
    "    tf.keras.layers.Dense(32, activation='relu'), \n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(1) \n",
    "])\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=10, validation_data=(X_test_scaled, y_test))\n",
    "\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Testing Loss')\n",
    "plt.title('Training vs. Testing Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0, 1)\n",
    "plt.savefig('fiftyepochsonly.png')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Metrics for Performance etc.\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"Validation Metrics:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d9afed-1e59-437e-b807-37f30c38c2b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "276bed33-baaf-4ff3-92ed-8545b8d1dbd8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cross-Validated Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9424ddaa-d1b9-4d5d-910c-3183aa3c7763",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = cleaned_df.drop(['Country', 'Code', 'Year'], axis = 1)\n",
    "X = df.drop(columns=['Happiness Score'])\n",
    "y = df['Happiness Score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(48, input_dim=X_train_scaled.shape[1], activation='relu'), \n",
    "    tf.keras.layers.Dense(32, activation='relu'), \n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(1) \n",
    "])\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=10, validation_data=(X_test_scaled, y_test))\n",
    "\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Testing Loss')\n",
    "plt.title('Training vs. Testing Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0, 1)\n",
    "plt.savefig('fiftyepochsonly.png')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Metrics for Performance etc.\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"Validation Metrics:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d02eba5-c234-4c6e-804f-9ff7f1d40e31",
   "metadata": {},
   "source": [
    "## Experiment: A Fake Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580941db-14c3-4209-b8a8-90f8389fc541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction for fake_country\n",
    "fake_country = pd.DataFrame({\n",
    "    'Adolescent Birth Rate (births per 1,000 women ages 15-19)': [6],\n",
    "    'Carbon dioxide emissions per capita (production) (tonnes)': [8],\n",
    "    'Expected Years of Schooling (years)': [18],\n",
    "    'Gender Development Index (value)': [0.98],\n",
    "    'Gross National Income Per Capita (2017 PPP$)': [40000],\n",
    "    'Life Expectancy at Birth (years)': [82],\n",
    "    'Maternal Mortality Ratio (deaths per 100,000 live births)': [8],\n",
    "    'Mean Years of Schooling (years)': [12],\n",
    "})\n",
    "\n",
    "fake_country_scaled = scaler.transform(fake_country)\n",
    "predicted_happiness_score = model.predict(fake_country_scaled)\n",
    "\n",
    "print(f\"Predicted Happiness Score for fake country: {predicted_happiness_score[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e056e60-23ac-44d1-919e-0ec6638d42bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_country # Fake country data line visualized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c915968-74a8-403e-b389-5672c7071ae3",
   "metadata": {},
   "source": [
    "## A Fake Country Across A Range Of Values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76a694f-32d4-4871-926b-0315252619a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Range of Incomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d84de0-da0f-40e1-b111-e0dc03f71a3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a range of income values from the current value to 100,000\n",
    "income_values = np.linspace(1500, 100000, num=100)\n",
    "\n",
    "# Initialize an array to store predicted happiness scores\n",
    "happiness_scores = []\n",
    "\n",
    "# Use the fake_country data as a template\n",
    "fake_country_template = fake_country.copy()\n",
    "\n",
    "for income in income_values:\n",
    "    # Update the income in the fake_country template\n",
    "    fake_country_template['Gross National Income Per Capita (2017 PPP$)'] = income\n",
    "    \n",
    "    # Scale the data\n",
    "    fake_country_scaled = scaler.transform(fake_country_template)\n",
    "    \n",
    "    # Predict happiness score for the updated data\n",
    "    predicted_score = model.predict(fake_country_scaled)\n",
    "    happiness_scores.append(predicted_score[0][0])\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(income_values, happiness_scores, marker='o', linestyle='-')\n",
    "plt.title(\"Effect of Income on Predicted Happiness Score\")\n",
    "plt.xlabel(\"Gross National Income Per Capita (2017 PPP$)\")\n",
    "plt.ylabel(\"Predicted Happiness Score\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c126ac-29bc-4615-a7ca-42b57c79d63f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Range of Educations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb73b90-a793-47cd-9cd7-61ed3241a1e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create a range of income values from the current value to 100,000\n",
    "income_values = np.linspace(2, 20, num=100)\n",
    "\n",
    "# Initialize an array to store predicted happiness scores\n",
    "happiness_scores = []\n",
    "\n",
    "# Use the fake_country data as a template\n",
    "fake_country_template = fake_country.copy()\n",
    "\n",
    "for income in income_values:\n",
    "    # Update the income in the fake_country template\n",
    "    fake_country_template['Mean Years of Schooling (years)'] = income\n",
    "    \n",
    "    # Scale the data\n",
    "    fake_country_scaled = scaler.transform(fake_country_template)\n",
    "    \n",
    "    # Predict happiness score for the updated data\n",
    "    predicted_score = model.predict(fake_country_scaled)\n",
    "    happiness_scores.append(predicted_score[0][0])\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(income_values, happiness_scores, marker='o', linestyle='-')\n",
    "plt.title(\"Effect of Education on Predicted Happiness Score\")\n",
    "plt.xlabel(\"Mean Years of Schooling (years)\")\n",
    "plt.ylabel(\"Predicted Happiness Score\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
